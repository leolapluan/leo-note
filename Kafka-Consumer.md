# ğŸ”‘ **5.1 Consumer trong Kafka System**
![image.png](https://images.viblo.asia/f0e4d8f4-2e36-4965-a4df-20b1bd5f2728.png)
### ğŸ” **Consumer lÃ m gÃ¬?**

Trong Kafka, **client (consumer)** Ä‘Ã³ng vai trÃ² quan trá»ng báº±ng cÃ¡ch:  
- **Äá»c dá»¯ liá»‡u tá»« cÃ¡c topic**: Láº¥y thÃ´ng Ä‘iá»‡p tá»« log phÃ¢n tÃ¡n cá»§a Kafka.  
- **Cung cáº¥p dá»¯ liá»‡u cho á»©ng dá»¥ng**: NhÆ° báº£ng Ä‘iá»u khiá»ƒn (metrics dashboards) hoáº·c cÃ¡c cÃ´ng cá»¥ phÃ¢n tÃ­ch.  
- **LÆ°u trá»¯ dá»¯ liá»‡u vÃ o há»‡ thá»‘ng khÃ¡c**: Äáº£m báº£o truy cáº­p lÃ¢u dÃ i hoáº·c xá»­ lÃ½ thÃªm.

### â± **Kiá»ƒm soÃ¡t tá»‘c Ä‘á»™ tiÃªu thá»¥**

Consumer trong Kafka cÃ³ lá»£i tháº¿ Ä‘áº·c biá»‡t: **kiá»ƒm soÃ¡t tá»‘c Ä‘á»™ tiÃªu thá»¥ dá»¯ liá»‡u**. Äiá»u nÃ y cho phÃ©p:  
- Consumer quyáº¿t Ä‘á»‹nh **lÆ°á»£ng dá»¯ liá»‡u cáº§n láº¥y** vÃ  **thá»i Ä‘iá»ƒm láº¥y dá»¯ liá»‡u**.  
- á»¨ng dá»¥ng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ **xá»­ lÃ½ táº£i thay Ä‘á»•i má»™t cÃ¡ch hiá»‡u quáº£**, trÃ¡nh bá»‹ quÃ¡ táº£i. 
## 5.1.1. **Consumer Options**:  
   - Sá»­ dá»¥ng cÃ¡c **deserializer** phÃ¹ há»£p cho khÃ³a vÃ  giÃ¡ trá»‹ (vÃ­ dá»¥: `StringDeserializer` hoáº·c `LongDeserializer`).  
   - Äáº£m báº£o cÃ¡c cáº¥u hÃ¬nh nhÆ° `bootstrap.servers`, `group.id`, vÃ  cÃ¡c tham sá»‘ timeout (`heartbeat.interval.ms`).  

2. **Xá»­ LÃ½ Dá»¯ Liá»‡u Tá»« Topic**:  
   - Poll dá»¯ liá»‡u tá»« topic `kinaction_promos`.  
   - Ãp dá»¥ng cÃ´ng thá»©c xá»­ lÃ½ giÃ¡ trá»‹ tá»« cÃ¡c sá»± kiá»‡n vá»›i **magic number** (vÃ­ dá»¥: nhÃ¢n 1.543).  

---

### ğŸ“‹ **Báº£ng Cáº¥u HÃ¬nh Consumer (Báº£ng 5.1)**

| **Key**                | **Má»¥c ÄÃ­ch**                                                                 |
|-------------------------|-----------------------------------------------------------------------------|
| **bootstrap.servers**   | Má»™t hoáº·c nhiá»u Kafka broker Ä‘á»ƒ káº¿t ná»‘i khi khá»Ÿi Ä‘á»™ng client.                |
| **value.deserializer**  | Cáº§n thiáº¿t Ä‘á»ƒ giáº£i mÃ£ (deserialization) giÃ¡ trá»‹ tá»« topic.                    |
| **key.deserializer**    | Cáº§n thiáº¿t Ä‘á»ƒ giáº£i mÃ£ (deserialization) khÃ³a tá»« topic.                       |
| **group.id**            | TÃªn Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tham gia má»™t consumer group.                            |
| **client.id**           | ID Ä‘á»ƒ xÃ¡c Ä‘á»‹nh má»™t ngÆ°á»i dÃ¹ng (chÆ°Æ¡ng 10 sáº½ sá»­ dá»¥ng).                       |
| **heartbeat.interval.ms** | Khoáº£ng thá»i gian giá»¯a cÃ¡c láº§n consumer gá»­i tÃ­n hiá»‡u (ping) Ä‘áº¿n group coordinator. |

---

### ğŸ–¥ï¸ **Code: Listing 5.1 - Consumer xá»­ lÃ½ khuyáº¿n mÃ£i**
```java
â€œpublic class KinactionStopConsumer implements Runnable {
     private final KafkaConsumer<String, String> consumer;
     private final AtomicBoolean stopping =
                              new AtomicBoolean(false);
     ...
 
    public KinactionStopConsumer(KafkaConsumer<String, String> consumer) {
      this.consumer = consumer;
    }
 
     public void run() {
         try {
             consumer.subscribe(List.of("kinaction_promos"));
             while (!stopping.get()) {                         â¶
                 ConsumerRecords<String, String> records =
                   consumer.poll(Duration.ofMillis(250));
                 ...
             }
         } catch (WakeupException e) {                         â·
             if (!stopping.get()) throw e;
         } finally {
             consumer.close();                                 â¸
         }
     }
 
     public void shutdown() {                                  â¹
         stopping.set(true);
         consumer.wakeup();
     }
}
  â¶ The variable stopping determines whether to continue processing.

  â· The client shutdown hook triggers WakeupException.

  â¸ Stops the client and informs the broker of the shutdown

  â¹ Calls shutdown from a different thread to stop the client properly
```
## 5.1.2 Hiá»ƒu rÃµ vá» Offset trong Kafka
![image.png](https://images.viblo.asia/3bfd0df4-1b6b-45a5-b4d8-67f49a4aebb0.png)
### ğŸ”¢ **Offset vÃ  cÃ¡ch hoáº¡t Ä‘á»™ng**  
- **Offset** lÃ  chá»‰ má»¥c xÃ¡c Ä‘á»‹nh vá»‹ trÃ­ thÃ´ng Ä‘iá»‡p trong log.  
- Offset **luÃ´n tÄƒng dáº§n** vÃ  khÃ´ng tÃ¡i sá»­ dá»¥ng.  
- Má»—i partition cÃ³ chuá»—i offset riÃªng, giáº£m nguy cÆ¡ vÆ°á»£t giá»›i háº¡n kiá»ƒu dá»¯ liá»‡u.

---
### ğŸ“Œ **auto.offset.reset vÃ  cÃ¡ch cáº¥u hÃ¬nh**  
- **Máº·c Ä‘á»‹nh**: `auto.offset.reset = latest`. Chá»‰ nháº­n cÃ¡c thÃ´ng Ä‘iá»‡p má»›i sau khi consumer khá»Ÿi Ä‘á»™ng.  
- **Cháº¿ Ä‘á»™ Ä‘á»c tá»« Ä‘áº§u**: DÃ¹ng flag `--from-beginning` Ä‘á»ƒ thiáº¿t láº­p `auto.offset.reset = earliest`, cho phÃ©p Ä‘á»c toÃ n bá»™ dá»¯ liá»‡u, ká»ƒ cáº£ thÃ´ng Ä‘iá»‡p cÅ©.

---

### ğŸ–¼ **PhÃ¢n bá»• partition vÃ  leader**  
- Má»—i topic Ä‘Æ°á»£c chia thÃ nh **nhiá»u partition**, má»—i partition cÃ³ má»™t leader replica.  
- **Consumer chá»‰ Ä‘á»c tá»« leader replica** cá»§a partition.
- <img width="660" alt="image" src="https://github.com/user-attachments/assets/b8249149-1796-4c4b-b739-80d1e6670a4e" />

- HÃ¬nh 5.3 minh há»a:  
  - Partition 1, 2, 3 cÃ³ leader trÃªn cÃ¡c broker khÃ¡c nhau.  
  - CÃ¡c báº£n sao (replica) Ä‘Æ°á»£c lÆ°u trá»¯ trÃªn cÃ¡c broker phá»¥ nhÆ°ng khÃ´ng Ä‘Æ°á»£c consumer Ä‘á»c trá»±c tiáº¿p.

---

### ğŸŒ **áº¢nh hÆ°á»Ÿng cá»§a sá»‘ lÆ°á»£ng partition**  
- **Nhiá»u partition** tÄƒng kháº£ nÄƒng xá»­ lÃ½ song song nhÆ°ng Ä‘i kÃ¨m chi phÃ­:  
  - **TÄƒng Ä‘á»™ trá»…** khi Ä‘á»“ng bá»™ giá»¯a cÃ¡c broker.  
  - **Tá»‘n tÃ i nguyÃªn bá»™ nhá»›** náº¿u consumer pháº£i xá»­ lÃ½ nhiá»u partition.  
- **Khuyáº¿n nghá»‹**: Lá»±a chá»n sá»‘ lÆ°á»£ng partition phÃ¹ há»£p vá»›i luá»“ng dá»¯ liá»‡u vÃ  yÃªu cáº§u á»©ng dá»¥ng.

---

### ğŸ“Š **PhÃ¢n bá»• consumer vÃ  partition**  
- **Sá»‘ lÆ°á»£ng consumer khÃ´ng nÃªn vÆ°á»£t quÃ¡ sá»‘ partition.**  
- HÃ¬nh 5.4 minh há»a: Vá»›i 4 consumer vÃ  3 partition, consumer dÆ° thá»«a sáº½ á»Ÿ tráº¡ng thÃ¡i chá» mÃ  khÃ´ng xá»­ lÃ½ dá»¯ liá»‡u.
  <img width="657" alt="image" src="https://github.com/user-attachments/assets/6dbd4774-d5c8-4202-92bb-a64c29b84234" />


---

### ğŸ“š **Kháº£ nÄƒng tÆ°Æ¡ng thÃ­ch vá»›i Apache ZooKeeper**  
- Kafka hiá»‡n khÃ´ng sá»­ dá»¥ng **ZooKeeper** cho consumer.  
- TrÆ°á»›c Ä‘Ã¢y, ZooKeeper Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ lÆ°u trá»¯ offset, nhÆ°ng hiá»‡n nay Kafka client Ä‘Ã£ loáº¡i bá» phá»¥ thuá»™c nÃ y.


# 5.2 How consumers interact 
**Consumer Group** lÃ  má»™t nhÃ³m gá»“m má»™t hoáº·c nhiá»u consumer lÃ m viá»‡c cÃ¹ng nhau Ä‘á»ƒ Ä‘á»c dá»¯ liá»‡u tá»« má»™t topic trong Kafka
**CÃ¹ng group**
CÃ¡c consumer phá»‘i há»£p lÃ m viá»‡c nhÆ° má»™t há»‡ thá»‘ng duy nháº¥t
**KhÃ¡c group**
CÃ¡c group lÃ m viá»‡c Ä‘á»™c láº­p, phÃ¹ há»£p vá»›i cÃ¡c logic xá»­ lÃ½ khÃ¡c nhau
## CÃ¡c Ä‘áº·c Ä‘iá»ƒm chÃ­nh cá»§a Consumer Groups:
**Phá»‘i há»£p (Coordination)**: CÃ¡c consumer trong cÃ¹ng má»™t nhÃ³m phá»‘i há»£p Ä‘á»ƒ Ä‘áº£m báº£o má»—i partition cá»§a topic chá»‰ Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi má»™t consumer duy nháº¥t trong nhÃ³m.
**Chia sáº» Offset**: CÃ¡c consumer trong cÃ¹ng má»™t nhÃ³m chia sáº» thÃ´ng tin offset (vá»‹ trÃ­ Ä‘á»c dá»¯ liá»‡u cuá»‘i cÃ¹ng) Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng cÃ³ dá»¯ liá»‡u bá»‹ Ä‘á»c láº·p láº¡i hoáº·c bá» sÃ³t.

VÃ­ dá»¥:
Giáº£ sá»­ báº¡n cÃ³ má»™t topic tÃªn lÃ  hr-data vá»›i 3 partitions:

Topic: hr-data
```
Partition 0: [message1, message2, message3]
Partition 1: [message4, message5]
Partition 2: [message6, message7, message8]
```

Náº¿u báº¡n cÃ³ 3 consumer trong cÃ¹ng má»™t nhÃ³m, má»—i consumer sáº½ Ä‘Æ°á»£c Kafka phÃ¢n cÃ´ng Ä‘á»c má»™t partition.
Náº¿u báº¡n thÃªm hoáº·c bá»›t consumer trong nhÃ³m, Kafka sáº½ tá»± Ä‘á»™ng phÃ¢n phá»‘i láº¡i cÃ¡c partition Ä‘á»ƒ Ä‘áº£m báº£o má»—i partition váº«n Ä‘Æ°á»£c xá»­ lÃ½ (rebalancing)

# 5.3 Tracking
á» cÃ¡c há»‡ thá»‘ng khÃ¡c, VD nhÆ° RabbitMQ, nÃ³ sáº½ xoÃ¡ record ngay sau khi consumer ack message. Tuy nhiÃªn Ä‘á»‘i vá»›i Kafka, nhá»¯ng record nÃ y sáº½ Ä‘Æ°á»£c lÆ°u láº¡i
Sá»± khÃ¡c biá»‡t quan trá»ng giá»¯a Kafka vá»›i cÃ¡c há»‡ thá»‘ng khÃ¡c, á»Ÿ viá»‡c cÃ¡ch consumer cÃ³ Ä‘Æ°á»£c message. Kafka consumer sáº½ poll dá»¯ liá»‡u tá»« Kafka vá», trong khi Ä‘Ã³ cÃ¡c há»‡ thá»‘ng khÃ¡c láº¡i thá»±c hiá»‡n viá»‡c push message tá»›i consumer cáº§n tiÃªu thá»¥. Quan sÃ¡t hÃ¬nh 5.5 phÃ­a dÆ°á»›i mÃ´ táº£ váº¥n Ä‘á» khi push message tá»›i consumer
<img width="653" alt="image" src="https://github.com/user-attachments/assets/f28da6a0-4b6a-408b-915d-91e3d4e6c25e" />
Váº¥n Ä‘á» 1: Do message bá»‹ xoÃ¡ sau khi ack, nÃªn chá»‰ cÃ³ thá»ƒ tiáº¿p tá»¥c consume tá»« message 3 (CÃ³ 1 váº¥n Ä‘á» Leo váº«n tháº¯c máº¯c, mÃ¬nh sáº½ Ä‘á»ƒ ngá» á»Ÿ Ä‘Ã¢y, táº¡i sao RabbitMQ khÃ´ng thá»±c hiá»‡n viá»‡c lÆ°u trá»¯ láº¡i message giá»‘ng nhÆ° Kafka lÃ m??? mÃ¬nh sáº½ research vÃ  bá»• sung dÆ°á»›i comment sau :>>)
Váº¥n Ä‘á» 2: Náº¿u cÃ³ nhiá»u consumer cáº§n tiÃªu thá»¥ cÃ¹ng 1 message, message Ä‘Ã³ sáº½ bá»‹ duplicate trong nhiá»u queue khÃ¡c nhau

2 váº¥n Ä‘á» trÃªn Ä‘á»u Ä‘Æ°á»£c Kafka giáº£i quyáº¿t, nÃ³ sáº½ chá»§ Ä‘á»™ng chÃ¬a message vÃ  consumer nÃ o cáº§n sáº½ tá»± chá»§ Ä‘á»™ng Ä‘i poll dá»¯ liá»‡u vá».

â€œit is important that the **offsets** and **partitions** are **specific** to a certain consumer groupâ€

## 5.3.1 Group coordinator
Group coordinator lÃ m viá»‡c vá»›i cÃ¡c consumer client Ä‘á»ƒ giá»¯ thÃ´ng tin vá» vá»‹ trÃ­ mÃ  má»™t nhÃ³m cá»¥ thá»ƒ Ä‘Ã£ Ä‘á»c trong topic
<img width="500" alt="image" src="https://github.com/user-attachments/assets/dec06095-f959-4d51-bd33-7c624a8e992e" />
HÃ¬nh 5.7 minh há»a má»™t scenario mÃ  cÃ¡c partition giá»‘ng nhau tá»“n táº¡i trÃªn ba broker khÃ¡c nhau cho hai consumer group khÃ¡c nhau, lÃ  kinaction_teamoffka0 vÃ  kinaction_teamsetka1. CÃ¡c consumer trong má»—i group sáº½ nháº­n má»™t báº£n sao dá»¯ liá»‡u riÃªng tá»« cÃ¡c partition trÃªn má»—i broker. ChÃºng khÃ´ng lÃ m viá»‡c cÃ¹ng nhau trá»« khi thuá»™c cÃ¹ng má»™t group
<img width="664" alt="image" src="https://github.com/user-attachments/assets/0b12a4f2-e49b-4509-a16b-f04b94ff3274" />
1 quy táº¯c cáº§n lÆ°u Ã½ lÃ  chá»‰ 1 consumer cá»§a 1 group cÃ³ thá»ƒ Ä‘á»c 1 partition táº¡i 1 thá»i Ä‘iá»ƒm (máº·c dÃ¹ 1 partition cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘á»c bá»Ÿi nhiá»u consumer)

HÃ¬nh 5.8 nháº¥n máº¡nh consumer 1 cÃ³ thá»ƒ Ä‘á»c tá»« 2 partition leader, trong khi consumer 2 chá»‰ cÃ³ thá»ƒ Ä‘á»c tá»« partition leader cÃ²n láº¡i. Má»—i partition chá»‰ Ä‘Æ°á»£c gÃ¡n cho má»™t consumer duy nháº¥t trong cÃ¹ng má»™t consumer group. Äiá»u nÃ y Ä‘Æ°á»£c cho lÃ  Ä‘á»ƒ trÃ¡nh viá»‡c nháº§m láº«n trong quáº£n lÃ½ offset vÃ  phÃ¢n phá»‘i dá»¯ liá»‡u

<img width="701" alt="image" src="https://github.com/user-attachments/assets/2bbf4f0b-782c-4659-8127-fcf41d2c2ce1" />

â€œ heartbeat.interval.ms, which determines the amount of pings to the group coordinator from consumers â€ 
Náº¿u heartbeat ngá»«ng, Ä‘iá»u nÃ y sáº½ loáº¡i bá» consumer khá»i group vÃ  kÃ­ch hoáº¡t cÆ¡ cháº¿ reblancing.

## 5.3.2 Partition assignment strategy (Chiáº¿n lÆ°á»£c assign partition)
* Range: dÃ¹ng alphabetical order (pháº§n dÆ° sáº½ dá»“n qua consumer Ä‘áº§u tiÃªn)
* RoundRobin: PhÃ¢n phá»‘i tuáº§n tá»±
* Sticky vÃ  CooperativeSticky: MÃ¬nh sáº½ k tÃ¬m hiá»ƒu á»Ÿ Ä‘Ã¢y

<img width="648" alt="image" src="https://github.com/user-attachments/assets/e62ea3d7-0101-4868-aec1-a9d9daff4f1a" />

# 5.4 Marking our place
# **Listing 5.4: Waiting on a Commit**  

```java
consumer.commitSync();               // â¶
# // Any code here will wait on line before
â¶ commitSync waits for a success or fail.
```

```java
public static void commitOffset(long offset,
                                int partition,
                                String topic,
                                KafkaConsumer<String, String> consumer) {
  OffsetAndMetadata offsetMeta = new OffsetAndMetadata(++offset, "");

  Map<TopicPartition, OffsetAndMetadata> kaOffsetMap = new HashMap<>();
  kaOffsetMap.put(new TopicPartition(topic, partition), offsetMeta);

  consumer.commitAsync(kaOffsetMap, (map, e) -> {     // â¶
    if (e != null) {
      for (TopicPartition key : map.keySet()) {
        log.info("kinaction_error: offset {}", map.get(key).offset());
      }
    } else {
      for (TopicPartition key : map.keySet()) {
        log.info("kinaction_info: offset {}", map.get(key).offset());
      }
    }
  });
}
â¶ A lambda that creates an OffsetCommitCallback instanceâ€
```

# 5.5 Compacted topic
â€œKafka compacts the partition log in a **background process**, and records with the same key might be removed except for the last oneâ€
Náº¿u requirement khÃ´ng quan trá»ng lá»‹ch sá»­ cá»§a dá»¯ liá»‡u, chá»‰ quan tÃ¢m tráº¡ng thÃ¡i má»›i nháº¥t. 
Äiá»u khiáº¿n cÃ¡c consumer dá»… gáº·p lá»—i nháº¥t khi Ä‘á»c tá»« má»™t compacted topic lÃ  chÃºng váº«n cÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c nhiá»u báº£n ghi cho cÃ¹ng má»™t key. LÃ m sao Ä‘iá»u nÃ y cÃ³ thá»ƒ xáº£y ra? VÃ¬ quÃ¡ trÃ¬nh compaction Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn cÃ¡c tá»‡p log lÆ°u trá»¯ trÃªn Ä‘Ä©a, nÃªn compaction cÃ³ thá»ƒ khÃ´ng nhÃ¬n tháº¥y táº¥t cáº£ cÃ¡c thÃ´ng Ä‘iá»‡p Ä‘ang náº±m trong bá»™ nhá»› khi thá»±c hiá»‡n compact.

Trong trÆ°á»ng há»£p cÃ³ nhiá»u value cho 1 key thÃ¬ client sáº½ xá»­ lÃ½, láº¥y cÃ¡i má»›i nháº¥t lÃ  oke con dÃª =))

# 5.6 Coding time
## Listing 5.6 Earliest offset
```java
Properties kaProperties = new Properties();
kaProperties.put("group.id", UUID.randomUUID().toString());        â¶
kaProperties.put("auto.offset.reset", "earliest");     â·
â¶ Creates a group ID for which Kafka does not have a stored offset
â· Uses the earliest offset retained in our logs
```
## **Listing 5.7: Latest Offset Configuration**  

```java
Properties kaProperties = new Properties();
kaProperties.put("group.id", 
                 UUID.randomUUID().toString());    // â¶
kaProperties.put("auto.offset.reset", "latest");   // â·
â¶ Creates a group ID for which Kafka does not have a stored offset
â· Uses the latest record offset
```
## **Listing 5.8: Seeking to an Offset by Timestamps**  

```java
...
Map<TopicPartition, OffsetAndTimestamp> kaOffsetMap = 
    consumer.offsetsForTimes(timeStampMapper);   // â¶
...
// We need to use the map we get
consumer.seek(partitionOne, 
              kaOffsetMap.get(partitionOne).offset());   // â·
â¶ Finds the first offset greater or equal to that timeStampMapper

â· Seeks to the first offset provided in kaOffsetMap
```
## **Listing 5.9: Audit Consumer Logic**

```java
// Disable auto commit
kaProperties.put("enable.auto.commit", "false");   // â¶

try (KafkaConsumer<String, String> consumer = 
        new KafkaConsumer<>(kaProperties)) {
    
    // Subscribe to the topic
    consumer.subscribe(List.of("kinaction_audit"));

    while (keepConsuming) {
        // Poll records from Kafka
        var records = consumer.poll(Duration.ofMillis(250));
        for (ConsumerRecord<String, String> record : records) {
            // Audit record process logic
            // ...

            // Create OffsetAndMetadata for the next offset
            OffsetAndMetadata offsetMeta = 
                new OffsetAndMetadata(++record.offset(), "");   // â·

            // Create map to store offsets for topic and partition
            Map<TopicPartition, OffsetAndMetadata> kaOffsetMap = 
                new HashMap<>();
            kaOffsetMap.put(
                new TopicPartition("kinaction_audit", record.partition()), 
                offsetMeta);   // â¸

            // Commit offsets synchronously
            consumer.commitSync(kaOffsetMap);   // â¹
        }
    }
}
â¶ Sets autocommit to false
â· Adding a record to the current offset determines the next offset to read.
â¸ Allows for a topic and partition key to be related to a specific offset
â¹ Commits the offsets
```
## **Listing 5.10: Alert Trending Consumer**

```java
// Enable auto-commit
kaProperties.put("enable.auto.commit", "true");     // â¶

// Configure key deserializer
kaProperties.put("key.deserializer",
  AlertKeySerde.class.getName());                   // â·

// Configure value deserializer
kaProperties.put("value.deserializer",
  "org.apache.kafka.common.serialization.StringDeserializer");

// Create KafkaConsumer instance
KafkaConsumer<Alert, String> consumer =
    new KafkaConsumer<Alert, String>(kaProperties);

// Subscribe to the topic
consumer.subscribe(List.of("kinaction_alerttrend"));

while (true) {
    // Poll for records
    ConsumerRecords<Alert, String> records =
        consumer.poll(Duration.ofMillis(250));

    for (ConsumerRecord<Alert, String> record : records) {
        // Process each alert record
        // ...
    }
}
â¶ Uses autocommit as lost messages are not an issue
â· AlertKeySerde key deserializer
```

## 5.11 Alert consumer
```java
kaProperties.put("enable.auto.commit", "false");
 
KafkaConsumer<Alert, String> consumer =
  new KafkaConsumer<Alert, String>(kaProperties);
TopicPartition partitionZero =
  new TopicPartition("kinaction_alert", 0);             â¶
consumer.assign(List.of(partitionZero));                â·
 
while (true) {
    ConsumerRecords<Alert, String> records =
      consumer.poll(Duration.ofMillis(250));
    for (ConsumerRecord<Alert, String> record : records) {
        // ...
        commitOffset(record.offset(),
          record.partition(), topicName, consumer);     â¸
    }
}
 
...
public static void commitOffset(long offset,int part, String topic,
  KafkaConsumer<Alert, String> consumer) {
    OffsetAndMetadata offsetMeta = new OffsetAndMetadata(++offset, "");
 
    Map<TopicPartition, OffsetAndMetadata> kaOffsetMap =
      new HashMap<TopicPartition, OffsetAndMetadata>();
    kaOffsetMap.put(new TopicPartition(topic, part), offsetMeta);
 
    OffsetCommitCallback callback = new OffsetCommitCallback() {
    ...
    };
    consumer.commitAsync(kaOffsetMap, callback);        â¹
}
â¶ Uses TopicPartition for critical messages

â· Consumer assigns itself the partition rather than subscribing to the topic
â¸ Commits each record asynchronously
â¹ The asynchronous commit uses the kaOffsetMap and callback arguments.
```
